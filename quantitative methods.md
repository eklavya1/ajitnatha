random markdown file .md extension h
How Interest rate is determined
(A) Risk Premium--Additional interest taken to compensate the risk.
(1)Default risk Premium--Can he pay me back?
(2)Liquidity Premium--How easy is it to convert it to cash?
(3)Maturity Risk premium--How long does he take to pay me back?
(B)Nominal Risk-Free rate--Minimum return an investor expects for any investment.
(1)Inflation Premium--How much inflation is expected over this period?
(2)Real risk free rate--Single period interest rate for a risk-free security  	

Interpretations of Interest Rate
(A)Required Rate of Return
(B)Discount Rate
(C)Opportunity Cost

[[future]] Value Formula= FV=PV(1+r)n
                      FV=[[future]] Value
                      PV=Present Value
                      n= Time Period
                      r= Interest rate
                      (1+r)n= [[future]] Value Factor
                      
Effective Annual Rate= (1+r)n-1                      
Effective Annual Rate= How much interest is effectively being paid in a whole year.
EAR cont= er-1
          e=mathematical constant=2.718
FV cont= PV* ern  (r and n are raised to the power of e)           		                                           
PV=FV/(1+r)n
FVn=A[(1+r)n-1/r]
              A=Regular cash flow
              r=interest rate
              N=No. of time periods
In case of Unequal cashflows add up all the individual cashflows 
Annuity- A finite set of level	sequential cashflows
Types of annuities-
                   (A) Ordinary annuities- Cashflow occurs at the end of each time period.
                   (B) Annuity Dues- Cashflow occuring at the beginning of each period.
                   (C) Perpetuities- It is like an ordinary annuity except that the cashflows are never ending.
                   
Present Value perpetuity formula- PV(Perp)=PMT/r


Statistics Fundamentals
(1) Measurement Scales
   (A) Nominal Scale
   (B) Ordinal Scale-Rank
   (C) Interval Scale-Rank, Measure
   (D) Ratio Scale--Rank, Measure, True Zero
   Descriptive Statistics-Consolidating a mass of data into useful information.
   Inferential Statistics- Making estimates about the population from a sample.
   
   Frequency Distribution Steps
   Step 1 - Define the intervals- Find the min. and max.
   Step 2 - Tally and count the observations
   Absolute Frequency- The actual count of no. of observations within each interval.
   
   Relative Frequency= Absolute Frequency/Total observations
   
If you don't want to use the recall function in calculator to calculate PV we can use this shortcut method instead
          After calculating the PV you can further move ahead by Step-1 Divide the PV value by 1.04
                                                                 Step-2 Press y(raise to power of x)          
                                                                 Step-3 Then Press 5 =
                                                                 Note- The above steps can be done only in AOS mode. 
                                                                 
Measures of Central Tendency
Population Mean= µ= ∑X/N          N=Population Size
Sample Mean= x̄ = Σx / n           n=Sample size                                                                        
Weighted Mean =  Σwx/Σw  w=weight x=value                                                          
Mode= most frequently occuring observation in the series
Modal Interval=Interval in which most no of observations occur or Interval with the highest frequency.    {Lower Limit<=X<Higher Limit}
                sum of middle elements/2 (If there are more than 1 mode value)                      
The advantage of using median over mean is that it is not skewed by outliers.
Harmomic Mean=  n / [(1/x1)+(1/x2)+(1/x3)+…+(1/xn)]  n=Total no. of observations
Geometric Mean= (X1*X2....Xn)1/n
To calculate average price paid per unit use harmonic mean.
To calculate appropriate annualised rate of return for n years use geometric mean.
Weighted Mean is calculated when the allocation/or value of returns is different
The sum of all the weights should be equal to 1 in case of weighted mean problem.
Mode is the only measure that can be used with nominal data like fund styles.
Geometric mean is mathematically correct than arithmetic mean but the arithmetic mean serves as the better estimator of [[future]] returns.
Quartiles divide the data set into quarters (25%)
Quintiles divide the data set into quints (20%)
Deciles divide the data set into tens (10%)
Percentiles divide the data set into hundreds (1%)
The average price paid per unit calculated by harmonic mean is slightly lower than that of calculated by the arithmetic mean, this mathematical fact is the basis claimed for the benefit of regular investments into mutual funds also known as Dollar cost averaging. 

Measures of Dispersion
Range=Highest value- Lowest Value
In Mean absolute Deviation the observations below the mean will be negative.
Mean absolute Deviation= ∑|xi−x¯¯¯|/N
Variance= σ2=∑(X-μ)2/N            N=Total no. of observations μ= Mean X=Variable value
Standard Deviation Formula= σ= √ Σ(X- μ)2/N
Population variance= σ2 = ∑(x – μ)2 / N
Population Standard deviation=  σ=√∑(x – μ)2 / N
Sample Standard deviation= s=√∑(x−xˉ)2/n-1
Sample Variance= S2​=∑(x−xˉ)2/n-1​​
Standard Deviation  ≥ Mean Absolute Deviation
Chebyshev's Inequality= The proportion of observations within K satndard deviations is atleast 1-1/K2
No. standard deviations= 1-1/K2 (k Square)
chebyshev is an application of standard deviation
Chebyshev can be used to calculate the endpoints of the interval that contains observations.
Coefficient of Variation=To address the issue of relative degree of variability of different data sets.
Coeeficient of variation= standard deviation/ Mean or risk per unit
​​Sharpe Ratio= r-rf/standard deviation     rf=risk-free rate
Normal Distribution Charecterstics= (A) Mean=Median
​                                    (B) The distribution can be completely described by its mean and variance
                                    (C) Around 68% of the observations lie between +1 and -1 standard deviation from the mean.
                                    (D) 95% between +2 and -2 
                                    (E) 99% between +3 and -3
                                    (F) It is symmetrical on both sides of the mean.
Skewness is the extent to which the distribution is not symmetrical
Positively skewed distribution has many outliers on its right tail.
Negatively skewed distribution has many outliers on its left tail.
Mean is more sensitive to extreme values than median.
In positively skewed Distribution=  Mean > Median > Mode
In Negatively skewed Distribution= Mode > Median > Mean
Sample Skewness formula= l/n * ∑Ni (Xi – X)3 / S3
Sk (skewness value) > 0.5 than it shows significant skewness.
Kurtosis is in which a distribution is more or less peaked than a normal distribution.
A distribution is leptokurtic when it is more peaked than a normal distribution.
A distribution is platykurtic when it is less peaked or flatter than a normal distribution.
A distribution is mesokutic when it has the same kurtosis as the normal distribution.
In a Leptokurtic distribution the tails are fatter as compared to the normal distribution that suggests it is more risky than normal distribution
Sample Kurtosis formula= l/n * ∑Ni (Xi – X)4 / S4
                                    
Probability Concepts                                    
A random variable is uncertain quantity or no.
Outcome is the observed value of a random variable.
Event is a single or a set of outcomes.
Mutually Exclusive events cannot happen at the same time.
Exhaustive Events are those which include all possible outcomes.
Defining Properties of Probability
                                  (A) If a set of events are mutually exclusive and exhaustive the sum of their probabilities is equal to 1.
                                  (B) The Probability of any event is between 0 and 1 .
 If probability is 0 then event will never happen.
 If probability is 1 then event will surely happen that also means that the outcome is not random.
 Methods or ways to determine probability.
 (A) Empirical-Analyses past data.
 (B) Subjective- Based on personal judgement.
 (C) A priori- Based on formal reasoning.
 A priori and empirical methods are objective because they do not vary from person to person.
 Probability can be stated as Odds.
  For ex- P(E)=0.2
          Odds FOR= P(E)/1-P(E)=1/4 (1 occurence of E for every 4 non-occurence)
          Odds AGAINST= 1-P(E)/P(E)=4/1 ($4 profit for every $1 wagered that gives $ 5 for every 1$  wagered)
Unconditional or Marginal Probability- Probability of an event regardless of past or [[future]] occurences of other events.
Conditional Probability-It limits to a specific condition.
Joint Probability P(AB) 
Multiplication Rule: P(AB)=P(A|B) * P(B) 
Independent Events: Events which the occurence of one has no influence on the occurence of the other.
Simplified multiplication rule for independent events= P(AB)= P(A) * P(B) A and B are likely independent 
Joint Probability : A ∩ B means that the joint probability is the intersection between A and B
A ∪  B  : The Union of A and B in joint Probability- It shows that atleast one event will occur
Addition Rule: P(A or B)= P(A) + P(B) - P(AB) 
Simplified Addition Rule: P(A or B)= P(A) + P(B) It is for mutually exclusive events.
Total Probability Rule: P(B)= P(BA) + P(BAcomp)
Applying Multiplication Rule P(B) = P(B|A) * P(A) + P(B|Acomp.) * P(Acomp.)
Mutually exclusive events are those which cannot happen at the same time.
Exhaustive events are those events that covers all possible outcomes.
When events are mutually exclusive and exhaustive than sum of their probabilities is 1: P(A) + P(B)= 1
Unconditional Proabbility is the probability of an event in the context of all possible outcomes.
Conditional Probability is the probability of an event in the context of another event.
In Joint probability is the probability of both events happening.
Multiplication Rule dictates the relationship between the Joint probability and unconditional probability.
Union is the probability of either events happening and the addition rule helps us to determine this.
Average Value for a random variable is called as expected value and the measure of its deviations is variance.
Expected Value Formula= E(X)= ΣP(X)X
Variance=  σ2(X)= ΣP(X)[X-E(X)]2
Conditional Expected Value Formula : E(X|S)= ΣP(X|S)X
Multiplication Rule: P(X|R)= P(XR)/ P(R) R=Probability of Recession (as an example) 
The Expected value of a weighted sum of a random variables equals the weighted sum of the expected values: E(WxX+WyY)= WxE(X) + WyE(Y) 
The returns of two assets X and Y are likely not independent from each other in the financial market so we have to use joint probability to calculate it.
Since the returns on assets are not independent from each other we have to calculate their co-variance.
Covariance is a measure of how 2 assets move together.
Co-variance Formula= Cov(X,Y)=E{X-E(X)][Y-E(Y)]}
Properties of Covariance- (A) It is a general representation of variance.                                 
                          (B) Cov(X,X)= Var(X)
                          (C) Range from negative infinity to positive infinity  
Returns move in opposite directions.
Correlation coefficient= Corr(X,Y)= Cov(X,Y)/√ Var(X) Var(Y)
Correlation ranges from -1 to +1
When there is perfect negative correlation or the answer of a calculation of correlation coefficient is negative then the other variable will be in positive and when answer is positive then the other variable will also be positive.
Portfolio Variance = σ2(WxX+WyY)=Wx2σ2(X)+Wy2σ2(Y)+2WxWyCov(X,Y)                                     
Bayes Formula= P(Event|Info)=P(Info|Event)*P(Event)/P(Info)                                    
Principles of counting help to determine the total no. of possibilities in a problem.
Multiplication Rule of Counting- The multiplication of the no. of ways at each step.
Multiplication Rule can be used to solve assigning problems.
n factorial= n*(n-1) * (n-2)*......*1=n!
Multinomial Formula=  No. of Ways= n!/n1!n2!......nk!    (If sequence is not important)
n choose r Formula= nCr=n!/r!(n-r)!   n=total elements so L1 has r elements than L2 has n-r elements.
Permutation Formula= nPr= n!/(n-r)!    (If sequence is important)

Common Probability Distributions

Discrete Random Variable                                               Continuous Random Variable
(A)No.of possible outcomes can be counted                            (A) No. of possible outcomes is infinite.
e.g.-no. of up days for a stock.                                         e.g. time for a stock to move +/-1%
(B)Probability Distribution Function: p(1)=P(X=1)=0.2                (B) Probability Density Function: f(1)= P(X=1)=0.2
(C)Cumulative Distribution Function: F(1)=P(X<=1)=0.2                     (C) Cumulative Distribution Function: F(1)=P(X<=1)=0.2   X=Random Variable

Discrete Uniform Random Variable
(A) All outcomes have equal probability of occuring.
(B) Sum of probabilities of all probable outcomes has to be 1.
(C) The cumulative distribution function has to start from 0 and end with 1.
Example of Discrete Distribution Function is Bernoulli Distribution in which there are only 2 outcomes. 
Binomial Distribution Formula: P(X=x)= nCx * px * (1-p)n-x (raise to the power of (1-p))  where X: no. of successes 
                                                                                                n: no. of trials
                                                                                                p: probability of success
 E(X)=np   E=Expected value
           n= No. of trials
           p= Probability of success
 Var(X)= np(1-p)
 Tracking Error= Total return of portfolio- Total return of associated index 
 
 Continuous Random Variable
 (A) Continuous Uniform Distributions
 -Equally likely outcomes
 -Sum of all the probabilties of all the possible outcomes must be 1: Σf(X)=1 (Any probability distribution function)
 -Area under the line=1
 for continuous uniform random variable f(X)= 1/(b-a) for a<x<b
 
 In Normal Distribution Kurtosis=3 
 Leptokurtic >3
 Platykurtic <3
 
 When the standard deviations are applied in a probability distribution then it gives the confidence intervals that the outcome will fall within such ranges.
 Their are 3 confidence intervals: 90% 95% 99%
 90%: Xbar-1.65s<X<Xbar+1.65s
 95%: Xbar-1.96s<X<Xbar+1.96s
 99%: Xbar-2.58s<X<Xbar+2.58s
 Z-Transformation/Z-value = Z=X-μ/σ This formula is used in calculating mean variance analysis.
 Shortfall Risk: Probability of return falling below threshold return.
 The Lower the z-value the lower the shortfall risk.
 Roy Safety First Ratio: SFR=E(Rp)-RL/σP      RL=Threshold value
 Higher the SFR value the lower the shortfall risk
 Lognormal Distribution
 Price relative or 1+Holding period return= FV/PV=eRccN (RccN is raised to the power of e)
 log(FV/PV)=Rcc * N
 FV/PV=eRccN = Log(FV/PV)= Log eRccN = Rcc * N
 If natural log of Y is normal, Y is a lognormal distribution.
-It is skewed towards the right with the long fat right tail.
-It can never take values below 0.
Lognormal distribution is used for modeling asset prices
Normal distribution is used in modeling asset returns.

Monte Carlo Simulation
It is a computer based technique in which probability distri butions play an integral role.
Step-1 Determine quantity of Interest
Step-2 Specify time horizon.                                                                                                            
Applications of Monte Carlo Simulation in Finance
-Valuing complex securities.
-Evaluating trading strategies.
-Calculate estimates of value at risk.
-Simulate pension fund assets and liabilities.
-Value assets that have non-normal returns distribution.
Limitations of Monte carlo simulation
-Complexity in modeling
-Results highly dependent of models and assumptions
-cannot provide analytical insights
Historical simulation advantage is that the results reflect actual frequencies from past data and the disadvantage is that it cannot do
"what if" analysis.
Unlike the monte carlo The Historical simulation has no random no. generator and the models are not prepared by an analyst
Sampling- Sampling an estimation is the process of making inferences about population parameters using sample statistics.
Simple Random Sampling- The goal of this method is that every element has equal probability to be selected.
Systematic Sampling
Whether systematic or random the simple random sampling may not be ideal in some cases.
Stratified Random sampling is the random selection from subgroups based on the distinguishing charecterstics from each subgroup.
Two types of data can be analysed by stratified random sampling (A) Time series data- Observations taken over a period of time.
                                                                (B) Cross sectional data- Observations taken at a single point in time.
Sampling error of the mean= Xbar- μ        μ= Population Mean Xbar= Sample Mean                                                          
Sampling error of the standard deviation= S-σ        σ=Population Standard Deviation S=Sample Std.Deviation
Central Limit Theorem- For simple random samples of size n from a population with mean μ and variance σ2, the sampling distribution of the sample mean approaches a normal distribution with mean μ and variance σ2/n.
As the sample size increases the sampling distribution is reduced or gets narrower when we look in graph.
As long as the sample size is greater than or equal to 30 the sampling distribution can be normal. 
When Population parameters are unknown, we may use the sample statistics to estimate it.
Mean of Sampling distribution Xbar= Mean of Population μ      df=n-1 df-degree of freedom
Variance of sampling distribution Xbar= Variance of population σ2/sample size.
Desirable properties of an Estimator- (A) Unbiased- Expected value of the estimator is equal to the parameter to be estimated.
                                      (B) Efficient- No other unbiased estimator has a sampling distribution with a smaller variance.
                                      (C) Consistent- Accuracy of the estimate increases as the sample size increases.
Types of estimators- (A) Point Estimate- Single value used to estimate population parameters.
                     (B) Confidence Interval- Range of values in which the population parameter is expected to fall within.
Confidence Interval= Point Estimate ± (Reliability factor * Standard error) 
Generalised Confidence Interval formula= Xbar ± Zα/2σXbar    α= Level of significance   1-α= Degree of confidence
Student's T- distribution is an alternative to the z-distribution and used when the z-statistic is not appropriate to use.
Student's T- distribution is less peaked and has fatter tails as compared to normal distribution.
The degree to which the distribution deviates from normal is defined by degrees of freedom.
The larger the Degree of freedom the closer the t-distribution approaches the normal distribution.
Degree of freedom=n-1
Z-table use z to find probability and t-table use probability to find t-value. 
The T- value is used to calculate confidence interval and perform hypothesis testing.
Criteria for selecting test statistic- (A) Population distribution normal? If Yes than find out that the population variance is known If yes than use z-statistic and if no then use t-statistic.
                                       (B) Population variance known?
                                       (C) Sample size greater than or equal to 30
If the population distribution is not normal than find that the sample size is greater than or equal to 30 and if it is less than 30 then the central limit theorem cannot be applied.
If the sample size is greater than or equal to 30 than we can use the z or t statistic based in the population variance is known or not.
standard error= standard deviation/√no. of observations or sample size
Point estimate is population mean or sample mean
For reliability factor select test statistic then find the significance level and the last step is to find the t or z-value.
If using the t table then degree of freedom is n-1 and if using z-value then use the figures of confidence intervals.

Biases in sampling
-Larger sample size is not necessarily better because (A) It may contain observations from a different population with different charecterstics and such differences may reduce the precision of population parameters.
-(B) obtaining extra observations may be costly.
Data mining bias occurs when the researchers overuse the same data to serach for patterns.
Sample selection bias occurs when some observations are excluded ususally because of unavailability, this makes the observed sample to be non-random making the conclusions flawed.
Example of sample selection bias is survivorship bias in mutual fund performance.
Time period Basis occurs when the time period which the data represent is too long or too short.

Hypothesis Testing is making inferences from the sample statistics.
Forming a Hypothesis-Step-1 State the Hypothesis
Step-2 Identify test statistic and its probability distribution.
Step-3 Specify significance level.
Step-4 State decision rule
Step-5 Collect and test data
Step-6 Make the statistical decision
Step-7 Make economic decision

Step-1 Null hypothesis H0- Hypothesis to be tested.      θ= θ0
                                                         θ<=θ0
                                                         θ≥θ0
Alternative Hypothesis HA- Hypothesis accepted when H0 is rejected.  θ ≠ θ0
                                                                     θ > θ0
                                                                     θ < θ0
Population parameter  θ Possible value  θ0
Step-2  Test Statistic- Value that is the basis for rejecting H0
Test statistic= Sample statistic-H0 value/standard error of sample statistic
Step-3 Type-1 Error- Rejection of the null hypothesis when it is actually true.
       Type-2 Error- Failure to reject the null hypothesis when it is actually false.
       P(type 1 error)= α
       P(type 2 error)= β
When α is set too low the probability of a type 2 error increases as we will reject the null hypothesis less often, including when it is false.
The only way to decrease both types of errors is to increase the sample size.
Step-4 If H0: θ<=0 in one tailed test and significance level is 5% then reject H0
If the test statistic falls at left of critical value then it is statistically insignificant we expect this if H0 is true.
If the test statistic falls in the right tail than it is statistically significant this is unlikely if H0 is true.
If H0 : θ ≥ 0 then it will be a left tailed distribution.
If H0: θ=0 then it will be a two tailed test.
Step-5 Ensuring the quality of the sample
-Check for measurement errors
-Avoid sample selection bias especially survivorship bias
-Be aware of time period bias.
Step-5 Draw the statistical info from above steps and make an statistical decision complying with it.
Step-6 The economic significance -In determining it factors like costs, taxes and risks are to be considered.
The P-value approach-alternative to hypothesis testing.
The P-value is the smallest level of significance for which the null hypothesis can be rejected.
Just the p-value is reported without selecting a significance level.
This approach allows the reader to make own conclusions on the significance of the results.

In the differences between means both the distributions must be normal.
Find out if both the populations are independent of each other and is Variance σ of population 1 = Variance σ of population 2 and if they are we can use the t-test where we can use the pooled estimator of common variance.
df=n1+n2-2 df= degree of freedom
Procedure to perform a hypothesis test is same as that for a single mean.
In case when variances of the two population are not same then use paired comparisons test.
Paired comparison test: The samples from population 1 have to be paired with the corresponding samples from population 2.
  d=X1-X2 Treat d as a single random variable and perform hypothesis testing on it as in the case of a single mean.
                                                                                             
Hypothesis Tests concerning variance 
(A) Chi-Square Test - Used for hypothesis tests concerning the variance of a normally distributed population.
 σ02(square) : Hypothesised value of the variance.
 Its distribution is asymmetrical and its shape approaches the normal distribution as the degrees of freedom increase.
 Test statistic for chi square:  X2 n-1= (n-1)S2/σ02   σ2=Variance of population S2=Variance of sample.
 (B) F-Test - Used for hypothesis tests concerning the equality of variances between two normally distributed populations and independent samples.
 Null hypothesis: σ1square= σ2square
                  σ1square2<=σ2square
                  σ1square ≥ σ2square
Alternate Hypothesis: σ1square not equal to σ2square
                      σ1square>σ2square
                      σ1square<σ2square
                      
The f-distribution is charecterised by degrees of freedom and is asymmetrical 
Test statistic: F=S1square/S2square   (assign the numerator with the higher value to force a right tail test as their is no f-table for negative values.
Parametric Tests- They are concerned with parameters.
                    -Their validity depends on a set of assumptions.
                    -For ex- chisquare, f-test etc.  
(C) Non Parametric Tests- They are not concerned with parameters and minimal assumptions are used.
When are the non parametric tests appropriate-(A) Distributional assumptions not met.                     
                                              (B) The data is ranked because the ranked data is not normally distributed and parametric tests require stronger scale than rank.
                                              (C) They are not concerned with parameter for example the problems where non-parametric tests are like this 
                                              (1) Is the sample random? (2) Is this sample from a population following a normal distribution?
Example of non parametric test often used in investment research is Spearman Rank Correlation Test which is used to test linear relationship between two variables.
Spearman rank correlation coefficent ranges between -1 and +1.
+1 represents perfect positive straight line relationship
-1 represents perfect inverse straight line relationship
0 represents no relationship.

Hypothesis tests concerning correlation
As the sample size n increases the magnitude of correlation r decreases
Null Hypothesis H0: ρ=0 When there is not a linear relationship between two variables.
Alternate Hypothesis HA: ρ≠ 0 when there is a linear relationship between two variables. ρ=correlation coefficient
Test statistic formula : t=r√(n-2)/√(1-r2) r=magnitude of correlation

